# -*- coding: utf-8 -*-
"""basecnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TROKQFeHlz4jdeVMGsEoo6jbOBoCl7Td

#Deep Learning Assignmenet
Implementation file by - M25MAC004, M25MAC008, M25MAC014, M25MAC016

#Dataset Selection - Fashion-MNIST Dataset is used for this assignment
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import torchvision
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import random
import time

# For Reproducibility
def set_seed(seed=56):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(56)

# ───Checing device for GPU  ──────────────────────────────────────────────────────────
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ───Loading Dataset ~downloading directly in the code file─────────────────────────────────────────────────────────
transform = transforms.Compose([
    transforms.ToTensor(),                          # [0,1], shape (1,28,28)
    transforms.Normalize((0.2860,), (0.3530,)),     # Fashion-MNIST mean/std
])

Train_set = datasets.FashionMNIST(root='./data', train=True,  download=True, transform=transform)
Test_set   = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)

"""#Details of the Training data set"""

print(f"Dataset Name: Fashion-MNIST - Details of the Train data")
print(f"Number of training samples: {len(Train_set)} ")
print(f"Image dimensions: {Train_set[0][0].shape} (C, H, W) ")
print(f"Number of classes: {len(Train_set.classes)}")
print(f"Classes: {Train_set.classes} ")

"""#Details of the Test data set"""

print(f"Dataset Name: Fashion-MNIST -Details of the Test data")
print(f"Number of training samples: {len(Test_set)} ")
print(f"Image dimensions: {Test_set[0][0].shape} (C, H, W) ")
print(f"Number of classes: {len(Test_set.classes)}")
print(f"Classes: {Test_set.classes} ")

"""#Train-Test split
using 50,000 Samples fro training and all 10000 samples for testing split.
"""

# Dataset split ~ 50 000 train / 10 000 val split
train_set, val_set = random_split(Train_set, [50000, 10000],
                                  generator=torch.Generator().manual_seed(56))

BATCH_SIZE = 128
Training_data = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)
Validation_data   = DataLoader(val_set,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
Testing_data  = DataLoader(Test_set,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

CLASS_NAMES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

import matplotlib.pyplot as plt
# Creating the visualization grid
figure = plt.figure(figsize=(10, 10))
cols, rows = 5, 5

#defining lablesas given in the original dataset for the plot lables
labels_map = {
    0: "T-shirt", 1: "Trouser", 2: "Pullover", 3: "Dress", 4: "Coat",
    5: "Sandal", 6: "Shirt", 7: "Sneaker", 8: "Bag", 9: "Ankle Boot"
}
for i in range(1, cols * rows + 1):
    # Select a random image from the dataset
    sample_idx = torch.randint(len(Train_set), size=(1,)).item()
    img, label = Train_set[sample_idx]

    # Plotting
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis("off")
    # Squeeze the tensor (1, 28, 28) to (28, 28) for grayscale display
    plt.imshow(img.squeeze(), cmap="gray")

plt.tight_layout()
plt.show()

"""# Drfining the train_prep_images

 To prepare images for training and to comply with the requirement that the input resolution must match dataset specifications, we modified the first layer of the chosen baseline architecture to accept 1-channel grayscale inputs and adjusted the final fully connected layer to 10 classes. All weights were initialized from scratch to ensure no pretrained data was used.

 ## Why this Function is Important:
 >As the standard architectures listed in the assignment (ResNet-18, VGG-16, VGG-19) were originally designed for the ImageNet dataset.
 There are two major technical mismatches between those standard models and your Fashion-MNIST dataset:+1Channel Mismatch: Standard ResNet/VGG models expect 3-channel (RGB) color images. Fashion-MNIST provides 1-channel (grayscale) images. Without this function to change the first layer's in_channels from 3 to 1, your code would crash with a runtime error.+2Resolution Mismatch: These models are designed for $224 \times 224$ pixel images. Fashion-MNIST is only $28 \times 28$. The train_prep_img function removes the maxpool layer (in ResNet) or modifies the pooling to ensure the internal feature maps don't become too small (zero-sized) before reaching the final layer.Output Classes: Standard models have 1000 output nodes (for ImageNet). This function updates the final nn.Linear layer to 10 nodes to match the categories in Fashion-MNIST
"""

def train_prep_img(model, device):
    if isinstance(model, torchvision.models.resnet.ResNet):
        # Modify first layer for 1-channel input
        original_conv1 = model.conv1
        model.conv1 = nn.Conv2d(
            in_channels=1,
            out_channels=original_conv1.out_channels,
            kernel_size=original_conv1.kernel_size,
            stride=original_conv1.stride,
            padding=original_conv1.padding,
            bias=original_conv1.bias is not None
        )
        # Remove maxpool for small images
        model.maxpool = nn.Identity()
        # Modify final layer for 10 classes
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, 10)
    elif isinstance(model, torchvision.models.vgg.VGG):
        # Modify first layer for 1-channel input
        original_conv0 = model.features[0]
        model.features[0] = nn.Conv2d(
            in_channels=1,
            out_channels=original_conv0.out_channels,
            kernel_size=original_conv0.kernel_size,
            stride=original_conv0.stride,
            padding=original_conv0.padding,
            bias=original_conv0.bias is not None
        )

        # Find all MaxPool2d layers and identify the indices of the ones to remove.
        pool_indices_to_remove = []
        for i, m in enumerate(model.features.children()):
            if isinstance(m, nn.MaxPool2d):
                pool_indices_to_remove.append(i)

        # Replace the last two MaxPool2d layers with Identity to prevent dimension collapse.
        # This allows 3 pooling layers for 28x28 -> 3x3 output, then avgpool to 1x1.
        if len(pool_indices_to_remove) >= 2:
            model.features[pool_indices_to_remove[-1]] = nn.Identity()
            model.features[pool_indices_to_remove[-2]] = nn.Identity()
        elif len(pool_indices_to_remove) == 1: # Fallback if there's only one pooling layer left and it's problematic
             model.features[pool_indices_to_remove[-1]] = nn.Identity()

        # Replace default AdaptiveAvgPool2d((7,7)) with (1,1) to handle varying
        # output sizes from modified features block and prepare for classifier.
        model.avgpool = nn.AdaptiveAvgPool2d((1, 1))

        # Reconstructs the classifier block to match the new input features.
        # The last convolutional layer in VGG features block typically outputs 512 channels.
        # After AdaptiveAvgPool2d((1,1)), the input to the classifier will be 512 * 1 * 1.
        num_ftrs = 512 * 1 * 1 # Assuming 512 output channels from the features block after avgpool(1,1)

        # Build a new, simpler classifier for Fashion-MNIST (10 classes).
        model.classifier = nn.Sequential(
            nn.Linear(num_ftrs, 256), # Reduced hidden layer size for efficiency
            nn.ReLU(True),
            nn.Dropout(0.5),
            nn.Linear(256, 10), # Output layer for 10 classes
        )

    else:
        raise ValueError("Unsupported model type for train_prep_img")

    return model.to(device)

from torchvision.models import resnet18
from torchvision.models import vgg16
from torchvision.models import vgg19

Model_ResNet = resnet18(weights=None)  # weights are none to comply with the no pretrained weights allowed
Model_ResNet_final = train_prep_img(Model_ResNet, device)

Model_Vgg16 = vgg16(weights=None)
Model_Vgg16_final= train_prep_img(Model_Vgg16, device)

Model_Vgg19 = vgg19(weights=None)
Model_Vgg19_final=train_prep_img(Model_Vgg19, device)

"""#We are declaring and defining a training pipeline that we would be calling for different models. this function trains and evalutes models and gives the summary."""

def run_training_pipeline(model, train_loader, val_loader, test_loader, criterion, optimizer, scheduler, device, epochs):
    best_val_acc = 0.0

    train_losses = []
    train_accs = []
    val_losses = []
    val_accs = []

    for epoch in range(epochs):
        # Training phase
        model.train()
        running_loss = 0
        correct = 0
        total = 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        train_loss = running_loss / len(train_loader)
        train_acc = 100. * correct / total

        # Evaluation phase
        model.eval()
        running_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                running_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        val_loss = running_loss / len(val_loader)
        val_acc = 100. * correct / total

        scheduler.step()

        train_losses.append(train_loss)
        train_accs.append(train_acc)
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        # Save best model
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), f"best_{model.__class__.__name__.lower()}_fmnist.pth")
            print("Saved Best Model")

        print(f"Epoch {epoch+1}:")
        print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

    # Final test evaluation
    model.eval()
    running_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    test_loss = running_loss / len(test_loader)
    test_acc = 100. * correct / total

    print(f"\nFinal Test Loss: {test_loss:.4f}")
    print(f"Final Test Accuracy: {test_acc:.2f}%")

    return train_losses, train_accs, val_losses, val_accs, test_loss, test_acc

"""#Creating a function for plotting"""

def plot_training_curves(train_losses, train_accs, val_losses, val_accs, test_acc, model_name):
    epochs_range = range(1, len(train_losses) + 1)

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Accuracy plot
    axes[0].plot(epochs_range, train_accs, 'o-', label='Training Accuracy',
                 color='#2563eb', markersize=4, linewidth=1.5)
    axes[0].plot(epochs_range, val_accs,   's-', label='Validation Accuracy',
                 color='#dc2626', markersize=4, linewidth=1.5)
    axes[0].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Accuracy', fontsize=12)
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)
    # Optional: Set a reasonable y-limit for accuracy
    # axes[0].set_ylim([min(min(train_accs), min(val_accs)) * 0.9, 1.0])

    # Loss plot
    axes[1].plot(epochs_range, train_losses, 'o-', label='Training Loss',
                 color='#2563eb', markersize=4, linewidth=1.5)
    axes[1].plot(epochs_range, val_losses,   's-', label='Validation Loss',
                 color='#dc2626', markersize=4, linewidth=1.5)
    axes[1].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Loss (Cross-Entropy)', fontsize=12)
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3)

    # Main title for the figure
    fig.suptitle(f'{model_name} on Fashion-MNIST  —  Test Accuracy: {test_acc:.2f}%',
                 fontsize=15, fontweight='bold', y=1.02)

    plt.tight_layout()

    # Save the figure
    filename = f'{model_name.lower().replace(' ', '_')}_training_curves.png'
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"Saved {filename}")

    plt.show()

print("Function 'plot_training_curves' defined.")

"""#Running VGG16 model

"""

criterion = nn.CrossEntropyLoss()

optimizer_Vgg16 = optim.SGD(
    Model_Vgg16_final.parameters(),
    lr=0.01,
    momentum=0.9,
    weight_decay=5e-4
)

scheduler_Vgg16 = optim.lr_scheduler.CosineAnnealingLR(
    optimizer_Vgg16,
    T_max=50
)

train_losses_vgg16, train_accs_vgg16, val_losses_vgg16, val_accs_vgg16, test_loss_vgg16, test_acc_vgg16 = run_training_pipeline(Model_Vgg16_final, Training_data, Validation_data, Testing_data, criterion, optimizer_Vgg16, scheduler_Vgg16, device, 15)

plot_training_curves(train_losses_vgg16, train_accs_vgg16, val_losses_vgg16, val_accs_vgg16, test_acc_vgg16, 'VGG16')

"""#Running VGG19 model


"""

criterion = nn.CrossEntropyLoss()

optimizer_Vgg19 = optim.SGD(
    Model_Vgg19_final.parameters(),
    lr=0.01,
    momentum=0.9,
    weight_decay=5e-4
)

scheduler_Vgg19 = optim.lr_scheduler.CosineAnnealingLR(
    optimizer_Vgg19,
    T_max=50
)

train_losses_vgg19, train_accs_vgg19, val_losses_vgg19, val_accs_vgg19, test_loss_vgg19, test_acc_vgg19 = run_training_pipeline(Model_Vgg19_final, Training_data, Validation_data, Testing_data, criterion, optimizer_Vgg19, scheduler_Vgg19, device, 15)

plot_training_curves(train_losses_vgg19, train_accs_vgg19, val_losses_vgg19, val_accs_vgg19, test_acc_vgg19, 'VGG19')

"""#Running the ResNEt Model"""

criterion = nn.CrossEntropyLoss()

optimizer_ResNet = optim.SGD(
    Model_ResNet_final.parameters(),
    lr=0.01,
    momentum=0.9,
    weight_decay=5e-4
)

scheduler_ResNet = optim.lr_scheduler.CosineAnnealingLR(
    optimizer_ResNet,
    T_max=50
)

train_losses_resnet, train_accs_resnet, val_losses_resnet, val_accs_resnet, test_loss_resnet, test_acc_resnet = run_training_pipeline(Model_ResNet_final, Training_data, Validation_data, Testing_data, criterion, optimizer_ResNet, scheduler_ResNet, device, 15)

plot_training_curves(train_losses_resnet, train_accs_resnet, val_losses_resnet, val_accs_resnet, test_acc_resnet, 'ResNet')

"""#Custom CNN Baseline model on Fashion-MNIST using PyTorch

"""

# ─── Custom CNN Architecture ─────────────────────────────────────────
class BaselineCNN(nn.Module):
    """
    Custom CNN for Fashion-MNIST:
    Two conv blocks → flatten → two FC layers.
    Block = Conv → BN → ReLU → Conv → BN → ReLU → MaxPool → Dropout
    """
    def __init__(self, num_classes=10):
        super().__init__()

        # Block 1
        self.block1 = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # (B,32,28,28)
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),  # (B,32,28,28)
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),                               # (B,32,14,14)
            nn.Dropout2d(0.25),
        )

        # Block 2
        self.block2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (B,64,14,14)
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # (B,64,14,14)
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),                               # (B,64,7,7)
            nn.Dropout2d(0.25),
        )

        # Classifier head
        self.classifier = nn.Sequential(
            nn.Flatten(),                                  # (B, 3136)
            nn.Linear(64 * 7 * 7, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes),                   # raw logits
        )

    def forward(self, x):
        x = self.block1(x)
        x = self.block2(x)
        x = self.classifier(x)
        return x

# ─── Running Custom CNN Baseline ─────────────────────────────────────
# Instantiate Model
Model_Custom_CNN = BaselineCNN().to(device)

# Setup Loss, Optimizer, and Scheduler (Using same params as VGG/ResNet for comparison)
criterion = nn.CrossEntropyLoss()

optimizer_Custom = optim.SGD(
    Model_Custom_CNN.parameters(),
    lr=0.01,
    momentum=0.9,
    weight_decay=5e-4
)

scheduler_Custom = optim.lr_scheduler.CosineAnnealingLR(
    optimizer_Custom,
    T_max=50
)

# Execute Training Pipeline
# Note: Using 15 epochs to match consistency in all experiments
train_losses_custom, train_accs_custom, val_losses_custom, val_accs_custom, test_loss_custom, test_acc_custom = run_training_pipeline(
    Model_Custom_CNN,
    Training_data,
    Validation_data,
    Testing_data,
    criterion,
    optimizer_Custom,
    scheduler_Custom,
    device,
    15
)

# Plotting results
plot_training_curves(
    train_losses_custom,
    train_accs_custom,
    val_losses_custom,
    val_accs_custom,
    test_acc_custom,
    'Custom Baseline CNN'
)

# Final Report
print(f"Custom Model Summary:")
print(f"Final Test Accuracy: {test_acc_custom:.2f}%")

"""#Experimenting on the Custom CNN Model ~ for contrained optimization

#Adding Data Augumentation
"""

# Modified transform for Training ONLY
# ─── Updated Transforms with Augmentation ────────────────────────
# Training transform: Includes augmentation to improve robustness
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),         # Randomly flip images horizontally
    transforms.RandomRotation(degrees=10),           # Rotate by +/- 10 degrees
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
])

# Validation/Test transform: No augmentation, only normalization
test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
])

# ─── Reload Datasets ──────────────────────────────────────────────
# We reload the base datasets with the different transforms
Train_set_aug = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)
Test_set_final = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)

# Split the training set again (maintaining the same seed for consistency)
train_set_aug, val_set_aug = random_split(Train_set_aug, [50000, 10000],
                                          generator=torch.Generator().manual_seed(56))

# Define Loaders
Training_data_aug = DataLoader(train_set_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
Validation_data_aug = DataLoader(val_set_aug, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
Testing_data_aug = DataLoader(Test_set_final, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# Instantiate a fresh Custom Model
Model_Custom_Aug = BaselineCNN().to(device)

# Setup Optimizer & Scheduler (Keeping same as custom cnn that is our baseline model for fair comparison)
optimizer_aug = optim.SGD(Model_Custom_Aug.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
scheduler_aug = optim.lr_scheduler.CosineAnnealingLR(optimizer_aug, T_max=50)
criterion = nn.CrossEntropyLoss()

# Run the Training Pipeline
# We use the same number of epochs (15) as the baseline
train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_loss_aug, test_acc_aug = run_training_pipeline(
    Model_Custom_Aug,
    Training_data_aug,
    Validation_data_aug,
    Testing_data_aug,
    criterion,
    optimizer_aug,
    scheduler_aug,
    device,
    15
)

# Plot & Compare
plot_training_curves(train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_acc_aug, 'Custom CNN + Augmentation')

print(f"Final Test Accuracy (with Augmentation): {test_acc_aug:.2f}%")

"""#Experimenting with Different Augumentations"""

# ─── Improved Augmentation Transforms ────────────────────────────
# Translation-invariance (Crop) and Occlusion-robustness (Erasing)
train_transform_improved = transforms.Compose([
    transforms.RandomCrop(28, padding=2),           # Adds 2px padding then crops back to 28x28
    transforms.RandomHorizontalFlip(p=0.5),         # Generally safe for Fashion-MNIST
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3)) # Forces model to find alternative cues
])

# Validation/Test transform remains the same (No augmentation)
test_transform_simple = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
])

#  _________Reloading Datasets and DataLoaders________________________
# Re-loading ensures we use the "official train-test splits" as required
Train_set_full = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform_improved)
Test_set_final = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform_simple)

# Use fixed seed 56 for the split to match previous baseline
train_set_imp, val_set_imp = random_split(Train_set_full, [50000, 10000],
                                          generator=torch.Generator().manual_seed(56))

Training_data_imp = DataLoader(train_set_imp, batch_size=128, shuffle=True, num_workers=2)
Validation_data_imp = DataLoader(val_set_imp, batch_size=128, shuffle=False, num_workers=2)
Testing_data_imp = DataLoader(Test_set_final, batch_size=128, shuffle=False, num_workers=2)

# Initialize and Train Improved Model ────────────────────────
# Instantiate a fresh version of your custom CNN
Model_Improved_Aug = BaselineCNN().to(device)

# Using the same optimizer/scheduler as your comparison models for a fair test
optimizer_imp = optim.SGD(Model_Improved_Aug.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
scheduler_imp = optim.lr_scheduler.CosineAnnealingLR(optimizer_imp, T_max=50)
criterion = nn.CrossEntropyLoss()

# Run the pipeline (using 15 epochs to match your previous experiments)
train_losses_imp, train_accs_imp, val_losses_imp, val_accs_imp, test_loss_imp, test_acc_imp = run_training_pipeline(
    Model_Improved_Aug,
    Training_data_imp,
    Validation_data_imp,
    Testing_data_imp,
    criterion,
    optimizer_imp,
    scheduler_imp,
    device,
    15
)

# -----------Visualization --------------------
plot_training_curves(
    train_losses_imp, train_accs_imp,
    val_losses_imp, val_accs_imp,
    test_acc_imp,
    'Improved Custom CNN (Crop + Erasing)'
)

print(f"Final Test Accuracy with Improved Augmentation: {test_acc_imp:.2f}%")
# Save the model state dictionary
torch.save(Model_Improved_Aug.state_dict(), 'improved_aug_custom_cnn.pth')
print("Saved: improved_aug_custom_cnn.pth")

"""#Going with Augumnetation with more epocs to test learning of the model

"""

# Modified transform for Training ONLY
# Updated Transforms with Augmentation
# Training transform: Includes augmentation to improve robustness
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),         # Randomly flip images horizontally
    transforms.RandomRotation(degrees=10),           # Rotate by +/- 10 degrees
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
])

# Validation/Test transform: No augmentation, only normalization
test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.2860,), (0.3530,)),
])

# Reload Datasets ──────────────────────────────────────────────
# We reload the base datasets with the different transforms
Train_set_aug = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)
Test_set_final = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)

# Split the training set again (maintaining the same seed for consistency)
train_set_aug, val_set_aug = random_split(Train_set_aug, [50000, 10000],
                                          generator=torch.Generator().manual_seed(56))

# Define Loaders
Training_data_aug = DataLoader(train_set_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
Validation_data_aug = DataLoader(val_set_aug, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
Testing_data_aug = DataLoader(Test_set_final, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

# Instantiate a fresh Custom Model
Model_Custom_Aug = BaselineCNN().to(device)

# Setup Optimizer & Scheduler (Keep same as baseline for fair comparison)
optimizer_aug = optim.SGD(Model_Custom_Aug.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
scheduler_aug = optim.lr_scheduler.CosineAnnealingLR(optimizer_aug, T_max=50)
criterion = nn.CrossEntropyLoss()

# Run the Training Pipeline
# We use the same number of epochs (15) as the baseline
train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_loss_aug, test_acc_aug = run_training_pipeline(
    Model_Custom_Aug,
    Training_data_aug,
    Validation_data_aug,
    Testing_data_aug,
    criterion,
    optimizer_aug,
    scheduler_aug,
    device,
    15
)

# Plot & Compare
plot_training_curves(train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_acc_aug, 'Custom CNN + Augmentation')

print(f"Final Test Accuracy (with Augmentation): {test_acc_aug:.2f}%")# 1. Instantiate a fresh Custom Model
Model_Custom_Aug = BaselineCNN().to(device)

# Setup Optimizer & Scheduler (Keep same as baseline for fair comparison)
optimizer_aug = optim.SGD(Model_Custom_Aug.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
scheduler_aug = optim.lr_scheduler.CosineAnnealingLR(optimizer_aug, T_max=50)
criterion = nn.CrossEntropyLoss()

# Run the Training Pipeline
# We use the same number of epochs (15) as the baseline
train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_loss_aug, test_acc_aug = run_training_pipeline(
    Model_Custom_Aug,
    Training_data_aug,
    Validation_data_aug,
    Testing_data_aug,
    criterion,
    optimizer_aug,
    scheduler_aug,
    device,
    30
)

# Plot & Compare
plot_training_curves(train_losses_aug, train_accs_aug, val_losses_aug, val_accs_aug, test_acc_aug, 'Custom CNN + Augmentation')

print(f"Final Test Accuracy (with Augmentation 30 Epochs): {test_acc_aug:.2f}%")

torch.save(Model_Improved_Aug.state_dict(), 'improved_aug_custom_cnn_moreepochs.pth')
print("Saved: improved_aug_custom_cnn_moreepochs.pth")

torch.save(Model_Custom_Aug.state_dict(), 'improved_aug_custom_cnn_moreepochs.pth')
print("Saved: improved_aug_custom_cnn_moreepochs.pth")